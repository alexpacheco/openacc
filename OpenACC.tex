\documentclass[c,mathserif,compress,xcolor=svgnames]{beamer} 
\mode<presentation>
{  
  \setbeamertemplate{background canvas}[vertical shading][bottom=blue!5,top=blue!5]
  \setbeamertemplate{navigation symbols}{}%{\insertsectionnavigationsymbol}
  \usetheme{LSU}
}

\usefonttheme{professionalfonts}
\usefonttheme{serif}

\usepackage{pgf,pgfarrows,pgfnodes,pgfautomata,pgfheaps,pgfshade}
\usepackage{amsmath,amssymb,amsfonts,subfigure,pifont}
\usepackage{multirow,multicol}
\usepackage{tabularx}
\usepackage{booktabs}
\usepackage{colortbl}
\usepackage{algorithm,algpseudocode}
\usepackage{etex}
\usepackage{fancyvrb,listings}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82} 
\lstset{%
language=bash,                % the language of the code
%basicstyle=\footnotesize,           % the size of the fonts that are used for the code
basicstyle=\fontsize{4.5}{5.5}\selectfont\ttfamily,
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
%frame=single,                   % adds a frame around the code
%rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
tabsize=2,                      % sets default tabsize to 2 spaces
%captionpos=b,                   % sets the caption-position to bottom
breaklines=true,                % sets automatic line breaking
breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
%title=\lstname,                   % show the filename of files included with \lstinputlisting;
% also try caption instead of title
keywordstyle=\color{blue},          % keyword style
commentstyle=\color{dkgreen},       % comment style
stringstyle=\color{mauve},         % string literal style
escapeinside={\%*}{*)},            % if you want to add LaTeX within your code
morekeywords={*,\dots,elif},              % if you want to add more keywords to the set
deletekeywords={\dots},              % if you want to delete keywords from the given language
%morecomment=[l]{//}
}
\lstset{%
language=csh,                % the language of the code
%basicstyle=\footnotesize,           % the size of the fonts that are used for the code
basicstyle=\fontsize{4.5}{5.5}\selectfont\ttfamily,
showspaces=false,               % show spaces adding particular underscores
showstringspaces=false,         % underline spaces within strings
showtabs=false,                 % show tabs within strings adding particular underscores
%frame=single,                   % adds a frame around the code
%rulecolor=\color{black},        % if not set, the frame-color may be changed on line-breaks within not-black text (e.g. comments (green here))
tabsize=2,                      % sets default tabsize to 2 spaces
captionpos=b,                   % sets the caption-position to bottom
breaklines=true,                % sets automatic line breaking
breakatwhitespace=false,        % sets if automatic breaks should only happen at whitespace
%title=\lstname,                   % show the filename of files included with \lstinputlisting;
% also try caption instead of title
keywordstyle=\color{blue},          % keyword style
commentstyle=\color{dkgreen},       % comment style
stringstyle=\color{mauve},         % string literal style
escapeinside={\%*}{*)},            % if you want to add LaTeX within your code
morekeywords={*,\dots,elif},              % if you want to add more keywords to the set
deletekeywords={\dots},              % if you want to delete keywords from the given language
%morecomment=[l]{//}
}
\lstdefinestyle{LINUX}
{
%    backgroundcolor=\color{black},
%    basicstyle=\tiny\ttfamily,
%    keywordsstyle=\color{blue},
%    morekeywords={Tutorials,BASH,scripts},
%    literate={>}{{\textcolor{blue}{>}}}1
%         {/}{{\textcolor{blue}{/}}}1
%         {./}{{\textcolor{black}{./ }}}1
%         {~}{{\textcolor{blue}{\textasciitilde}}}1,
}

\lstdefinestyle{customc}{
  belowcaptionskip=1\baselineskip,
  breaklines=true,
  xleftmargin=\parindent,
  language=C,
  showstringspaces=false,
  basicstyle=\scriptsize\ttfamily,
  keywordstyle=\bfseries\color{green!40!black},
  commentstyle=\upshape\color{red!90!white},
  identifierstyle=\color{blue},
  stringstyle=\color{orange},
}
\lstdefinelanguage{OmpFortran}[]{Fortran}{
   rulesepcolor=\color{black},
   %
   extendedchars=true,
   %
   morecomment=[l] [\bfseries\color{red!90!white}]{!\$omp},
   morecomment=[l] [\bfseries\color{red!90!white}]{c\$omp},
   morecomment=[l] [\bfseries\color{red!90!white}]{*\$omp},
   morecomment=[l] [\bfseries\color{red!90!white}]{!\$acc},
   morecomment=[l] [\bfseries\color{red!90!white}]{c\$acc},
   morecomment=[l] [\bfseries\color{red!90!white}]{*\$acc},
}[comments]

\lstdefinelanguage{OmpC}[]{OmpFortran}{
   rulesepcolor=\color{black},
   %
   extendedchars=true,
   %
   morecomment=[l] [\bfseries\color{red!90!white}]{\#pragma\ omp},
   morecomment=[l] [\bfseries\color{red!90!white}]{\#pragma\ acc},
}[comments]

\lstset{escapechar=@,style=customc}
\lstset{literate=%
   *{0}{{{\color{blue}0}}}1
    {1}{{{\color{blue}1}}}1
    {2}{{{\color{blue}2}}}1
    {3}{{{\color{blue}3}}}1
    {4}{{{\color{blue}4}}}1
    {5}{{{\color{blue}5}}}1
    {6}{{{\color{blue}6}}}1
    {7}{{{\color{blue}7}}}1
    {8}{{{\color{blue}8}}}1
    {9}{{{\color{blue}9}}}1
}

\algrenewcommand\algorithmicfunction{\textbf{program}}
\algblockdefx[Program]{Program}{EndProgram}[1]{\textbf{program} \textsc{#1}}[1]{\textbf{end program} \textsc{#1}}
\algloopdefx[doloop]{Do}[1]{\textbf{do} #1}
\algcblockdefx[doloop]{If}{Do}{EndDo}
[1]{\textbf{do} #1}{\textbf{end do}}


\usepackage{tikz}
\usetikzlibrary{shapes,arrows,matrix}
\usetikzlibrary{calc}
\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}
\usepackage[latin1]{inputenc}
\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage[normalem]{ulem}
% \usepackage{movie15} 

\hypersetup{
  pdftitle={Introduction to OpenACC},
  pdfauthor={Alexander B. Pacheco, User Services Consultant, Louisiana State University}
}                                                         
\usepackage{times}
\usepackage[T1]{fontenc}
\usepackage{graphicx}

\setbeamercovered{dynamic}
\beamersetaveragebackground{DarkBlue!2}
\beamertemplateballitem

\definecolor{DarkGreen}{rgb}{0.0,0.3,0.0}
\definecolor{Blue}{rgb}{0.0,0.0,0.8} 
\definecolor{dodgerblue}{rgb}{0.1,0.1,1.0}
\definecolor{indigo}{rgb}{0.41,0.1,0.0}
\definecolor{seagreen}{rgb}{0.1,1.0,0.1}
\DeclareSymbolFont{extraup}{U}{zavm}{m}{n}
%\DeclareMathSymbol{\vardiamond}{\mathalpha}{extraup}{87}
%\DeclareMathSymbol{\vardiamond}{\mathalpha}{extraup}{87}
\newcommand{\cmark}{\ding{51}}
\newcommand{\xmark}{\ding{55}}
\newcommand{\smark}{\ding{77}}
\newcommand*\vardiamond{\textcolor{tigerspurple}{%
  \ensuremath{\blacklozenge}}}
\newcommand*\up{\textcolor{green}{%
  \ensuremath{\blacktriangle}}}
\newcommand*\down{\textcolor{red}{%
  \ensuremath{\blacktriangledown}}}
\newcommand*\const{\textcolor{darkgray}%
  {\textbf{--}}}
\newcommand*\enter{\tikz[baseline=-0.5ex] \draw[<-] (0,0) -| (0.5,0.1);}
\newcommand{\bftt}[1]{\textbf{\texttt{#1}}}
\newcommand{\lstfortran}[1]{\lstinline[language={[90]Fortran},basicstyle=\footnotesize\ttfamily]|#1|}
\newcommand{\lstc}[1]{\lstinline[language=C,basicstyle=\footnotesize\ttfamily]|#1|}
\newcommand{\Verblue}[1]{\Verb[formatcom=\color{blue},commandchars=\\\{\}]!#1!}
\newcommand{\Verbred}[1]{\Verb[formatcom=\color{red},commandchars=\\\{\},mathescape]|#1|}
\newcommand{\Verbindigo}[1]{\Verb[formatcom=\color{indigo},fontsize=\fontsize{7.5}{8}\selectfont,commandchars=\\\{\}]!#1!}

\setbeamercolor{uppercol}{fg=white,bg=red!30!black}%
\setbeamercolor{lowercol}{fg=black,bg=red!15!white}%
\setbeamercolor{uppercol1}{fg=white,bg=blue!30!black}%
\setbeamercolor{lowercol1}{fg=black,bg=blue!15!white}%%
\setbeamercolor{uppercol2}{fg=white,bg=green!30!black}%
\setbeamercolor{lowercol2}{fg=black,bg=green!15!white}%
\newenvironment{colorblock}[4]
{
\setbeamercolor{upperblock}{fg=#1,bg=#2}
\setbeamercolor{lowerblock}{fg=#3,bg=#4}
\begin{beamerboxesrounded}[upper=upperblock,lower=lowerblock,shadow=true]}
{\end{beamerboxesrounded}}
\newenvironment{ablock}[0]
{
\begin{beamerboxesrounded}[upper=uppercol,lower=lowercol,shadow=true]}
{\end{beamerboxesrounded}}
\newenvironment{bblock}[0]
{
\begin{beamerboxesrounded}[upper=uppercol1,lower=lowercol1,shadow=true]}
{\end{beamerboxesrounded}}
\newenvironment{eblock}[0]
{
\begin{beamerboxesrounded}[upper=uppercol2,lower=lowercol2,shadow=true]}
{\end{beamerboxesrounded}}

% Fix font size of nested itemize/enumerate
\setbeamerfont{itemize/enumerate body}{}
\setbeamerfont{itemize/enumerate subbody}{size=\scriptsize}
\setbeamerfont{itemize/enumerate subsubbody}{size=\scriptsize}

\title[OpenACC]{Introduction to OpenACC}


\author[Alex Pacheco]{\large{Alexander~B.~Pacheco}}
       
\institute[HPC Training: Spring 2014] {\inst{}\footnotesize{User Services Consultant\\LSU HPC \& LONI\\sys-help@loni.org}}

\date[\insertframenumber/\inserttotalframenumber\hfill\hspace{1.5cm}]{\scriptsize{HPC Training Spring 2014\\Louisiana State University\\Baton Rouge\\March 26, 2014}}
     
\subject{Talks}
\keywords{LONI \& LSU HPC Computing Resources, OpenACC Programming}
% This is only inserted into the PDF information catalog. Can be left
% out. 




% If you have a file called "university-logo-filename.xxx", where xxx
% is a graphic format that can be processed by latex or pdflatex,
% resp., then you can add a logo as follows:

% Main Logo on bottom left
\pgfdeclareimage[height=0.5cm]{institute-logo}{its-logo}
\logo{\pgfuseimage{institute-logo}}
% University Logo on top left
\pgfdeclareimage[height=0.55cm]{university-logo}{LSUGeauxPurp}
\tllogo{\pgfuseimage{university-logo}}
% Logo at top right
\pgfdeclareimage[height=0.55cm]{its-logo}{LONI}
\trlogo{\pgfuseimage{its-logo}}
% Logo at bottom right
\pgfdeclareimage[height=0.5cm]{hpc-logo}{cct-logo}
\brlogo{\pgfuseimage{hpc-logo}}

% for the list of parts
\makeatletter
%\AtBeginPart{%
%    \addtocontents{parttoc}{\protect\beamer@partintoc{\the\c@part}{\beamer@partnameshort}{\the\c@page}}%
%    \frame{\partpage}%
%}
\newcommand{\parttableofcontents}{\@starttoc{parttoc}}
\newcommand{\beamer@partintoc}[3]{#2\par}
\makeatother


% Delete this, if you do not want the table of contents to pop up at
% the beginning of each subsection:
% \AtBeginSection[]
% {
%   \begin{frame}<beamer>
%    \frametitle{{Outline}}
%    \scriptsize
%    \tableofcontents[currentsection,currentsubsection]
%   \end{frame}
% }

\begin{document}
\footnotesize

\tikzstyle{every picture}+=[remember picture]
\frame{\titlepage}

%\footnotesize
%\begin{frame}[label=toc,squeeze,allowframebreaks]
%  \scriptsize
%  \frametitle{{Outline}}
%  \tableofcontents
%\end{frame}


%\part{Introduction}
%\section{Introduction}
%\begin{frame}<0>
%  \frametitle{\small Goals}
%  \large{
%  \begin{block}{}
%    \begin{itemize}
%      \item Acquaint users with the concepts of shared memory parallelism.
%      \item Acquaint users with the basics of programming with OpenMP.
%    \end{itemize}
%  \end{block}
%  }
%\end{frame}

\begin{frame}{\small What is OpenACC?}
  \begin{bblock}{}
    \begin{itemize}
      \item OpenACC Application Program Interface describes a collection of compiler directive to specify loops and regions of code in standard C, C++ and Fortran to be offloaded from a host CPU to an attached accelerator.
      \item provides portability across operating systems, host CPUs and accelerators
    \end{itemize}
  \end{bblock}
\end{frame}

\begin{frame}[allowframebreaks]{\small OpenACC}
  \begin{eblock}{The Standard for GPU Directives}
    \begin{description}
      \item[Simple:] Directive are the easy path to accelerate compute intensive applications
      \item[Open:] OpenACC is an open GPU directives standard, making GPU programming straightforwards and portable across parallel and multi-core processors
      \item[Powerful:] GPU directives allow complete access to the massive parallel power of a GPU
    \end{description}
  \end{eblock}
  \framebreak
  \begin{eblock}{High Level}
    \begin{itemize}
      \item Compiler directives to specify parallel regions in C \& Fortran
      \begin{itemize}
        \item Offload parallel regions
        \item Portable across OSes, host CPUs, accelerators, and compilers
      \end{itemize}
      \item Create high-level heterogenous programs
      \begin{itemize}
        \item Without explicit accelerator intialization
        \item Without explicit data or program transfers between host and accelerator
      \end{itemize}
    \end{itemize}
  \end{eblock}
  \begin{eblock}{High Level $\cdots$ with low-level access}
    \begin{itemize}
      \item Programming model allows programmers to start simple
      \item Compiler gives additional guidance
      \begin{itemize}
        \item Loop mappings, data location and other performance details
      \end{itemize}
      \item Compatible with other GPU languages and libraries
      \begin{itemize}
        \item Interoperate between CUDA C/Fortran and GPU libraries
        \item e.g. CUFFT, CUBLAS, CUSPARSE, etc
      \end{itemize}
    \end{itemize}
  \end{eblock}
\end{frame}

\begin{frame}{\small Why OpenACC}
  \begin{eblock}{}
    \begin{itemize}
      \item Directives are easy and powerful.
      \item Avoid restructuring of existing code for production applications.
      \item Focus on expressing parallelism.
    \end{itemize}
  \end{eblock}
  \vspace{1cm}
  \begin{ablock}{}
    \begin{center}
      \vspace{0.1cm}
      \Large{\color{red!80!black}OpenACC is not GPU Programming}\\
      \vspace{1cm}
      \Large{\color{red!80!black}OpenACC is Expressing Parallelism in your code}
    \end{center}
  \end{ablock}
\end{frame}

\begin{frame}{Exercises:}
  \begin{itemize}
    \item Did you attend/review the trainings on C/C++ or Modern Fortran?
    \item Recall the following three exercises:
    \begin{enumerate}
      \item SAXPY: Generalized vector addition
      \item Matrix Multiplication
      \item Calculate pi by Numerical Integration
    \end{enumerate}
  \end{itemize}
\end{frame}

\begin{frame}{\small SAXPY}
  \begin{itemize}
    \item SAXPY is a common operation in computations with vector processors included as part of the BLAS routines
    \item[] $y\leftarrow \alpha x + y$
%    \item SAXPY is a combination of scalar multiplication and vector addition
    \item Write a SAXPY code to multiply a vector with a scalar.
  \end{itemize}
  \begin{algorithm}[H]
    \caption{Pseudo Code for SAXPY}
    \begin{algorithmic}
      \Program{saxpy}{}
      \State $n \gets$ some large number
      \State $x(1:n) \gets$ some number say, 1
      \State $y(1:n) \gets$ some other number say, 2
      \State $a \gets$ some other number ,say, 3
      \Do{$i \gets 1\cdots n$}
      \State $y_i \gets y_i + a * x_i$
      \EndDo
      \EndProgram{saxpy}
    \end{algorithmic}
  \end{algorithm}
\end{frame}

\begin{frame}[allowframebreaks]{Matrix Multiplication}
  \begin{itemize}
    \item Most Computational code involve matrix operations such as matrix multiplication.
    \item Consider a matrix {\bf C} which is a product of two matrices {\bf A} and {\bf B}:
    \item[] Element {\it i,j} of {\bf C} is the dot product of the $i^{th}$ row of {\bf A} and $j^{th}$ column of {\bf B}
    \item Write a MATMUL code to multiple two matrices.
  \end{itemize}
  \begin{center}
    \includegraphics[width=0.3\textwidth]{../OpenMP/matmul}
  \end{center}

  \begin{algorithm}[H]
    \caption{Pseudo Code for MATMUL}
    \begin{algorithmic}
      \Program{matmul}{}
      \State $m,n \gets$ some\,large\,number $\le 1000$
      \State Define $a_{mn}, b_{nm}, c_{mm}$
      \State $a_{ij} \gets i+j; b_{ij} \gets i-j; c_{ij} \gets 0$
      \Do{$i \gets 1\cdots m$}
      \Do{$j \gets 1\cdots m$}
      \State $c_{i,j} \gets \sum^{n}_{k=1} a_{i,k}*b_{k,j}$
      \EndDo
      \EndDo
      \EndProgram{matmul}
    \end{algorithmic}
  \end{algorithm}
\end{frame}

\begin{frame}[allowframebreaks]{Calculate pi by Numerical Integration}
  \begin{columns}
    \column{5cm}
    \begin{itemize}
      \item We know that
      \begin{align*}
        \int^1_0 \dfrac{4.0}{(1+x^2)}\, dx = \pi
      \end{align*}
      \item So numerically, we can approxiate pi as the sum of a number of rectangles
      \begin{align*}
        \sum^N_{i=0}\,F(x_i)\Delta x \approx \pi
      \end{align*}
      \item[] \fontsize{4}{5}{ Meadows et al, A ``hands-on'' introduction to OpenMP, SC09 }
    \end{itemize}
    \column{5cm}
    \begin{center}
      \includegraphics[width=4cm]{../OpenMP/pi}
    \end{center}
  \end{columns}

  \begin{algorithm}[H]
    \caption{Pseudo Code for Calculating Pi}
    \begin{algorithmic}
        \Function{calculate\_pi}{}
        \State $step \gets 1/n$
        \State $sum \gets 0$
        \Do{$i \gets 0\cdots n$}
        \State $x \gets (i+0.5)*step; sum \gets sum + 4/(1+x^2)$
        \EndDo
        \State $pi \gets sum * step$
        \EndFunction
    \end{algorithmic}
  \end{algorithm}
\end{frame}

\begin{frame}[fragile]{\small Simple Example {\color{black}I}}
  \begin{eblock}{Serial Code}
    \lstinputlisting[basicstyle=\fontsize{5}{6}\selectfont\ttfamily,language=OmpFortran]{./openmp/saxpy/solution/saxpy.f90} 
  \end{eblock}
\end{frame}
\begin{frame}[fragile]{\small Simple Example {\color{black}II}}
  \begin{eblock}{OpenMP Code}
    \lstinputlisting[basicstyle=\fontsize{5}{6}\selectfont\ttfamily,language=OmpFortran]{./openmp/saxpy/solution/saxpy_omp.f90} 
  \end{eblock}
\end{frame}
\begin{frame}[fragile]{\small Simple Example {\color{black}III}}
  \begin{eblock}{OpenACC Code}
    \lstinputlisting[basicstyle=\fontsize{5}{6}\selectfont\ttfamily,language=OmpFortran]{./openmp/saxpy/solution/saxpy_acc.f90} 
  \end{eblock}
\end{frame}
\begin{frame}[fragile]{\small Simple Example {\color{black}IV}}
  \begin{eblock}{CUDA Fortran Code}
    \lstinputlisting[basicstyle=\fontsize{5}{6}\selectfont\ttfamily,language=OmpFortran]{./openmp/saxpy/solution/saxpy_cuda.f90} 
  \end{eblock}
\end{frame}

\begin{frame}[fragile]{\small Simple Example {\color{black}V}}
  \begin{eblock}{Compile}
    {\tiny
      \begin{Verbatim}
[apacheco@mike1 2013-LONI]$ pgf90 -o saxpy saxpy.f90
[apacheco@mike1 2013-LONI]$ pgf90 -mp -o saxpy_omp saxpy_omp.f90
[apacheco@mike1 2013-LONI]$ pgf90 -acc -ta=nvidia -o saxpy_acc saxpy_acc.f90
[apacheco@mike1 2013-LONI]$ pgf90 -o saxpy_cuda saxpy.cuf
      \end{Verbatim}
    }
  \end{eblock}
  \begin{eblock}{Speed Up}
    \begin{center}
      \begin{tabular}{|cccc|}
        \hline
        Algorithm & Device & Time (s) & Speedup \\
        \hline
        Serial & Xeon E5-2670 & 0.986609 & 1\\
        OpenMP (8 threads) & Xeon E5-2670 & 0.241465 & 4.1x\\
        OpenACC & M2090 & 0.059418 & 16.6x\\
        CUDA & M2090 & 0.005205 & 189.5x\\
        \hline
      \end{tabular}
    \end{center}
  \end{eblock}
\end{frame}

\begin{frame}{\small OpenACC Execution Model}
  \begin{eblock}{}
    \begin{itemize}
      \item Application code runs on the CPU (sequential, shared or distributed memory)
      \item OpenACC directives indicate that the following block of compute intensive code needs to be offloaded to the GPU or accelerator.
    \end{itemize}
    \vspace{-0.5cm}
    \include{openacc-exec}
  \end{eblock}
\end{frame}

\begin{frame}[fragile]
  \frametitle{\small Building Block of OpenACC}
  \begin{eblock}{}
    \begin{itemize}
      \item Program directives
        \begin{itemize}
          \item Syntax
            \begin{itemize}
              \item C/C++: \Verbred{\#pragma acc <directive> [clause]}
              \item Fortran: \Verbred{!\$acc <directive> [clause]}
            \end{itemize}
          \item Regions
          \item Loops
          \item Synchronization
          \item Data Structure
          \item $\cdots$
        \end{itemize}
      \item Runtime library routines
%      \item Environment variables
    \end{itemize}
  \end{eblock}
\end{frame}

\begin{frame}[fragile]{\small Clauses}
  \begin{itemize}
    \item \Verbred{if (condition)}
    \item \Verbred{async (expression)}
    \item data management clauses
    \begin{itemize}
      \item \Verbred{copy($\cdots$),copyin($\cdots$), copyout($\cdots$)}
      \item \Verbred{create($\cdots$), present($\cdots$)}
      \item \Verbred{present\_or\_copy\{,in,out\}($\cdots$)} or \Verbred{pcopy\{,in,out\}($\cdots$)}
      \item \Verbred{present\_or\_create($\cdots$)} or \Verbred{pcreate($\cdots$)}
    \end{itemize}
    \item \Verbred{reduction(operator:list)}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{\small Runtime Libraries}
  \begin{itemize}
    \item System setup routines
    \begin{itemize}
      \item \Verbred{acc\_init(acc\_device\_nvidia)}
      \item \Verbred{acc\_set\_device\_type(acc\_device\_nvidia)}
      \item \Verbred{acc\_set\_device\_num(acc\_device\_nvidia)}
    \end{itemize}
    \item Synchronization routines
    \begin{itemize}
      \item \Verbred{acc\_async\_wait(int)}
      \item \Verbred{acc\_async\_wait\_all()}
    \end{itemize}
  \end{itemize}
\end{frame}

%\begin{frame}<0>{\small Environment Variables}
%  \begin{itemize}
%    \item OMP\_NUM\_THREADS
%    \item OMP\_SCHEDULE
%    \item OMP\_STACKSIZE
%    \item OMP\_DYNAMIC
%    \item OMP\_NESTED
%    \item OMP\_WAIT\_POLICY
%    \item more $\cdots$
%  \end{itemize}
%\end{frame}

\begin{frame}[fragile]{\small OpenACC kernels directive}
  \begin{columns}
    \column{0.65\textwidth}
    \begin{itemize}
      \item[C:] \Verbred{\#pragma acc kernels [clause]}
      \item[Fortran] \Verbred{!\$acc kernels [clause]}
      \item The kernels directive expresses that a region may contain parallelism and the compiler determines what can be safely parallelized.
      \item The compiler breaks code in the kernel region into a sequence of kernels for execution on the accelerator device.
      \item For the codes on the right, the compiler identifies 2 parallel loops and generates 2 kernels.
      \item {\color{red}What is a kernel?} {\color{DarkGreen}A function that runs in parallel on the GPU.}
      \item When a program encounters a kernels contruct, it will launch a sequence of kernels in order on the device.
    \end{itemize}
    \column{0.33\textwidth}
    \begin{eblock}{}
      \lstinputlisting[basicstyle=\tiny\ttfamily,language=OmpFortran,firstline=98,lastline=107]{openmp/tmp.f90}
      \lstinputlisting[basicstyle=\tiny\ttfamily,language=OmpC,firstline=50,lastline=60]{openmp/tmp.c}
    \end{eblock}
  \end{columns}
\end{frame}

\begin{frame}[fragile]{\small OpenACC Parallel Directive}
  \begin{columns}
    \column{0.65\textwidth}
    \begin{itemize}
      \item The {\bf parallel} directive identifies a block of code as having parallelism.
      \item Compiler generates a parallel kernel for that loop.
      \item[C:] \Verbred{\#pragma acc parallel [clauses]}
      \item[Fortran:] \Verbred{!\$acc parallel [clauses]}
    \end{itemize}
    \column{0.33\textwidth}
    \begin{eblock}{}
      \lstinputlisting[basicstyle=\tiny\ttfamily,language=OmpFortran,firstline=127,lastline=136]{openmp/tmp.f90}
      \lstinputlisting[basicstyle=\tiny\ttfamily,language=OmpC,firstline=61,lastline=71]{openmp/tmp.c}
    \end{eblock}
  \end{columns}
\end{frame}

\begin{frame}[fragile]{\small OpenACC Loop Directive}
  \begin{columns}
    \column{0.65\textwidth}
    \begin{itemize}
      \item Loops are the most likely targets for Parallelizing.
      \item The Loop directive is used within a parallel or kernels directive identifying a loop that can be executed on the accelerator device.
      \item[C:] \Verbred{\#pragma acc loop [clauses]}
      \item[Fortran:] \Verbred{!\$acc loop [clauses]}
      \item The loop directive can be combined with the enclosing parallel or kernels
      \item[C:] \Verbred{\#pragma acc kernels loop [clauses]}
      \item[Fortran:] \Verbred{!\$acc parallel loop [clauses]}
      \item The loop directive clauses can be used to optimize the code. This however requires knowledge of the accelerator device.
      \item[Clauses:] gang, worker, vector, num\_gangs, num\_workers
    \end{itemize}
    \column{0.33\textwidth}
    \begin{eblock}{}
      \lstinputlisting[basicstyle=\tiny\ttfamily,language=OmpFortran,firstline=139,lastline=143]{openmp/tmp.f90}
      \lstinputlisting[basicstyle=\tiny\ttfamily,language=OmpC,firstline=72,lastline=75]{openmp/tmp.c}
    \end{eblock}
  \end{columns}
\end{frame}

\begin{frame}{\small OpenACC parallel vs. kernels}
  \begin{columns}
    \column{0.4\textwidth}
    \begin{bblock}{PARALLEL}
      \begin{itemize}
        \item Requires analysis by programmer to ensure safe parallelism.
        \item Straightforward path from OpenMP
      \end{itemize}
    \end{bblock}
    \column{0.4\textwidth}
    \begin{bblock}{KERNELS}
      \begin{itemize}
        \item Compiler performs parallel analysis and parallelizes what it believes is safe.
        \item Can cover larger area of code with single directive.
      \end{itemize}
    \end{bblock}
  \end{columns}
  \begin{itemize}
    \item[] Both approaches are equally valid and can perform equally well.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \begin{columns}[t]
    \column{0.5\textwidth}
    \lstinputlisting[basicstyle=\fontsize{4}{5}\selectfont\ttfamily,language=OmpFortran]{openmp/saxpy/nodataregion/saxpy_acc.f90} 
    \column{0.5\textwidth}
    \lstinputlisting[basicstyle=\fontsize{4}{5}\selectfont\ttfamily,language=OmpC]{openmp/saxpy/nodataregion/saxpy_acc.c} 
  \end{columns}
\end{frame}

\scriptsize
\begin{frame}[fragile]
  \frametitle{\small Compilation}
  \begin{itemize}
    \item C: \Verbindigo{pgcc -acc [-Minfo=accel] [-ta=nvidia] -o saxpyc\_acc saxpy\_acc.c}
    \item Fortran 90:
    \Verbindigo{pgf90 -acc [-Minfo=accel] [-ta=nvidia] -o saxpyf\_acc saxpy\_acc.f90}
  \end{itemize}
  \begin{bblock}{Compiler Output}
    {\fontsize{5}{6}\selectfont
      \begin{Verbatim}
[apacheco@mike1 nodataregion]$ pgcc -acc -ta=nvidia -Minfo=accel  -o saxpyc_acc saxpy_acc.c
main:
     19, Generating present_or_copyin(x[0:500000000])
         Generating present_or_copy(y[0:500000000])
         Generating NVIDIA code
         Generating compute capability 1.0 binary
         Generating compute capability 2.0 binary
         Generating compute capability 3.0 binary
     21, Loop is parallelizable
         Accelerator kernel generated
         21, #pragma acc loop gang, vector(128) /* blockIdx.x threadIdx.x */
[apacheco@mike1 nodataregion]$ pgf90 -acc -ta=nvidia -Minfo=accel -o saxpyf_acc saxpy_acc.f90
saxpy:
     17, Accelerator kernel generated
         18, !$acc loop gang, vector(256) ! blockidx%x threadidx%x
     17, Generating present_or_copy(y(1:500000000))
         Generating present_or_copyin(x(1:500000000))
         Generating NVIDIA code
         Generating compute capability 1.0 binary
         Generating compute capability 2.0 binary
         Generating compute capability 3.0 binary
[apacheco@mike1 nodataregion]$
      \end{Verbatim}
    }
  \end{bblock}
\end{frame}

\begin{frame}[fragile]{\small Running}
  \begin{itemize}
    \item The PGI compiler provides automatic instrumentation when {\color{orange}PGI\_ACC\_TIME=1} at runtime
  \end{itemize}
  \begin{bblock}{}
    \begin{Verbatim}[fontsize=\fontsize{5}{6}\selectfont,commandchars=\\\{\}]
[apacheco@mike407 nodataregion]$ PGI_ACC_TIME=1 ./saxpyc_acc
SAXPY Time: 6.369176

Accelerator Kernel Timing data
/ddnB/work/apacheco/2013-LONI/openmp/saxpy/nodataregion/saxpy_acc.c
  main  NVIDIA  devicenum=0
    time(us): 1,029,419
    19: compute region reached 1 time
        19: data copyin reached 2 times
             device time(us): total={\textcolor{red}{667,515}} max=339,175 min=328,340 avg=333,757
        21: kernel launched 1 time
            grid: [65535]  block: [128]
             device time(us): total={\textcolor{red}{57,999}} max=57,999 min=57,999 avg=57,999
            elapsed time(us): total={\textcolor{red}{58,014}} max=58,014 min=58,014 avg=58,014
        25: data copyout reached 1 time
             device time(us): total={\textcolor{red}{303,905}} max=303,905 min=303,905 avg=303,905
[apacheco@mike407 nodataregion]$ PGI_ACC_TIME=1 ./saxpyf_acc
SAXPY Time:        6.488910

Accelerator Kernel Timing data
/ddnB/work/apacheco/2013-LONI/openmp/saxpy/nodataregion/saxpy_acc.f90
  saxpy  NVIDIA  devicenum=0
    time(us): 1,018,988
    17: compute region reached 1 time
        17: data copyin reached 2 times
             device time(us): total={\textcolor{red}{655,958}} max=327,991 min=327,967 avg=327,979
        17: kernel launched 1 time
            grid: [65535]  block: [256]
             device time(us): total={\textcolor{red}{59,148}} max=59,148 min=59,148 avg=59,148
            elapsed time(us): total={\textcolor{red}{59,165}} max=59,165 min=59,165 avg=59,165
        21: data copyout reached 1 time
             device time(us): total={\textcolor{red}{303,882}} max=303,882 min=303,882 avg=303,882
    \end{Verbatim}
  \end{bblock}
\end{frame}

\begin{frame}
  \begin{columns}
    \column{0.8\textwidth}
    \begin{eblock}{}
      \begin{tabular}{|c|c|c|c|c|}
        \hline
        Execution& \multicolumn{2}{c|}{C}& \multicolumn{2}{c|}{Fortran} \\
        \cline{2-5}
        &  Time & SpeedUp & Time & Speedup \\
        \hline
        Serial & 0.511232 & & 0.969819 & \\
        OpenMP (8 Threads) & 0.180301 & 2.84 & 0.237585 & 4.08 \\
        OpenACC (M2090) & 9.211521 & 0.06 & 9.188178 & 0.11 \\
          \hline
      \end{tabular}
    \end{eblock}
  \end{columns}
  \begin{itemize}
    \item What's going with OpenACC code?
    \item Why even bother with OpenACC if performance is so bad?
  \end{itemize}
\end{frame}

\begin{frame}{\small Offloading a Parallel Kernel}
  \include{kernel}
\end{frame}

\begin{frame}[fragile]{\small Defining data regions}
  \begin{itemize}
    \item The data construct defines a region of code in which GPU arrays remain on the GPU and are shared among all kernels in that region
  \end{itemize}
  \begin{columns}
    \column{9cm}
  \begin{eblock}{}
    \begin{columns}
      \column{3.5cm}
      \begin{lstlisting}[basicstyle=\tiny\ttfamily,language=OmpFortran]
!$acc data [clause]
    !$acc parallel loop
       ...
    !$acc end parallel loop
    ...
!$acc end data
      \end{lstlisting}
      \column{0.5cm}
      \fontsize{55}{20}\selectfont{\color{tigerspurple}\}}
      \column{3cm}
      Arrays used within the data region will remain on the GPU until the end of the data region.
    \end{columns}
  \end{eblock}
  \end{columns}
\end{frame}

\begin{frame}{\small Data Clauses}
  \begin{description}
    \item[copy(list)] Allocates memory on GPU and copies data from host to GPU when entering region and copies data to the host when exiting region.
    \item[copyin(list)] Allocates memory on GPU and copies data from host to GPU when entering region.
    \item[copyout(list)] Allocates memory on GPU and copies data to the host when exiting region.
    \item[create(list)] Allocates memory on GPU but does not copy.
    \item[present(list)] Data is already present on GPU from another containing data region.
  \end{description}
  \begin{itemize}
    \item Other clauses: {\color{tigerspurple}present\_or\_copy[in|out]}, {\color{tigerspurple}present\_or\_create}, {\color{tigerspurple}deviceptr}.
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{\small Array Shaping}
  \begin{itemize}
    \item Compiler sometime cannot determine size of arrays
    \begin{itemize}
      \item Must specify explicitly using the data clauses and array "shape"
    \end{itemize}
    \item[C] \Verbred{\#pragma acc data copyin(a[0:size]), copyout(b[s/4:3*s/4])}
    \item[Fortran] \Verbred{!\$acc data copyin(a(1:size)), copyout(b(s/4:3*s/4))}
    \item Note: data clauses can be used on data, parallel or kernels
  \end{itemize}
\end{frame}

\begin{frame}[fragile]{\small Update Construct}
  \begin{itemize}
    \item Used to update existing data after it has changed in its corresponding copy (e.g. upate device copy after host copy changes).
    \item Move data from GPU to host, or host to GPU.
    \item Data movement can be conditional and asynchronous.
    \item Fortran
    \item[] \Verbred{!\$acc update [clause $\cdots$]}
    \item C
    \item[] \Verbred{\#pragma acc update [clause $\cdots$]}
    \item Clause
    \begin{itemize}
      \item \Verbred{host(list)}
      \item \Verbred{device(list)}
      \item \Verbred{if(expression)}
      \item \Verbred{async(expression)}
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \begin{columns}[t]
    \column{0.5\textwidth}
    \lstinputlisting[basicstyle=\fontsize{4}{5}\selectfont\ttfamily,language=OmpFortran]{openmp/saxpy/solution/saxpy_acc.f90} 
    \column{0.5\textwidth}
    \lstinputlisting[basicstyle=\fontsize{4}{5}\selectfont\ttfamily,language=OmpC]{openmp/saxpy/solution/saxpy_acc.c} 
  \end{columns}
\end{frame}

\begin{frame}{\small SAXPY using data clause}
%  \begin{columns}
%    \column{0.5\textwidth}
%    \begin{eblock}{}
%      \lstinputlisting[basicstyle=\fontsize{3}{3.5}\selectfont\ttfamily,language=OmpFortran]{openmp/saxpy/solution/saxpy_acc.f90}
%    \end{eblock}
%    \column{0.5\textwidth}
%    \begin{eblock}{}
%      \lstinputlisting[basicstyle=\fontsize{3}{3.5}\selectfont\ttfamily,language=OmpC]{openmp/saxpy/solution/saxpy_acc.c}
%    \end{eblock}
%  \end{columns}
  \begin{columns}
    \column{0.8\textwidth}
    \begin{eblock}{}
      \begin{tabular}{|c|c|c|c|c|}
        \hline
        Execution& \multicolumn{2}{c|}{C}& \multicolumn{2}{c|}{Fortran} \\
        \cline{2-5}
        &  Time & SpeedUp & Time & Speedup \\
        \hline
        Serial & 0.510000 & & 0.986609 & \\
        OpenMP (8 Threads) & 0.179959 & 2.83 & 0.241465 & 4.09 \\
        OpenACC (M2090) & 0.058131 & 8.77 & 0.059418 & 16.61 \\
          \hline
      \end{tabular}
    \end{eblock}
  \end{columns}
\end{frame}

\begin{frame}{\small Exercise: Matrix Multiplication}
  \begin{columns}
    \column{0.7\textwidth}
    \begin{eblock}{C}
      \begin{tabular}{|c|c|c|c|}
        \hline
        Execution & Time & SpeedUp & GFlops/s \\
        \hline
        Serial & 6.227 &  & 0.964 \\
        OpenMP (8 Threads) & 0.823 & 7.566 & 7.290 \\
        OpenMP (16 Threads) & 0.445 & 13.993 & 13.493 \\
        OpenACC & 0.188 & 33.122 & 31.917 \\
        \hline
      \end{tabular}
    \end{eblock}
    \begin{eblock}{Fortran}
      \begin{tabular}{|c|c|c|c|}
        \hline
        Execution & Time & SpeedUp & GFlops/s \\
        \hline
        Serial & 7.112 & & 0.844 \\
        OpenMP (8 Threads) & 0.931 & 7.639 & 6.445 \\
        OpenMP (16 Threads) & 0.494 & 14.397 & 12.146 \\
        OpenACC & 0.214 & 33.234 & 28.037 \\
        \hline
      \end{tabular}
    \end{eblock}
  \end{columns}
%  \begin{columns}
%    \column{0.5\textwidth}
%    \begin{eblock}{}
%      \lstinputlisting[basicstyle=\fontsize{3}{3.5}\selectfont\ttfamily,language=OmpFortran]{openmp/matmul/solution/matmul_acc.f90}
%    \end{eblock}
%    \column{0.5\textwidth}
%    \begin{eblock}{}
%      \lstinputlisting[basicstyle=\fontsize{3}{3.5}\selectfont\ttfamily,language=OmpC]{openmp/matmul/solution/matmul_acc.c}
%    \end{eblock}
%  \end{columns}
\end{frame}

\begin{frame}[fragile,allowframebreaks]{\small Reduction}
  \begin{itemize}
    \item Reduction clause is allowed on \textit{parallel} and \textit{loop} constructs
  \end{itemize}
  \begin{eblock}{Fortran}
    \begin{lstlisting}[basicstyle=\tiny\ttfamily,language=OmpFortran]
!$acc parallel reduction(operation: var)
  structured block with reduction on var
!$acc end parallel
    \end{lstlisting}
  \end{eblock}
  \begin{eblock}{C}
    \begin{lstlisting}[basicstyle=\tiny\ttfamily,language=OmpC]
#pragma acc kernels reduction(operation: var) {
  structured block with reduction on var
}
    \end{lstlisting}
  \end{eblock}

  \begin{eblock}{}
    \begin{center}
      \begin{tabular}{|c|c|c|}
        \hline
        \multicolumn{3}{|c|}{Fortran}\\
        \hline
        Execution & Time & SpeedUp \\
        \hline
        Serial & 133.782 & 1 \\
        OpenMP (8 Threads) & 17.303 & 7.73 \\
        OpenACC & 0.149 & 897.87 \\
        \hline
        \multicolumn{3}{|c|}{C}\\
        \hline
        Execution & Time & SpeedUp \\
        \hline
        Serial & 134.214 & 1 \\
        OpenMP (8 Threads) & 17.3379 & 7.74 \\
        OpenACC & 0.151 & 888.83 \\
        \hline
        
      \end{tabular}
    \end{center}
  \end{eblock}
\end{frame}

\begin{frame}{\small Further Speedups}
  \begin{bblock}{}
    \begin{itemize}
      \item OpenACC gives us more detailed control over parallelization
      \begin{itemize}
        \item Via \textbf{gang}, \textbf{worker} and \textbf{vector} clauses
      \end{itemize}
      \item By understanding more about specific GPU on which you're running, using these clauses may allow better performance.
      \item By understanding bottlenecks in the code via profiling, we can reorganize the code for even better performance.
    \end{itemize}
  \end{bblock}
\end{frame}

\begin{frame}{\small General Principles: Finding Parallelism in Code}
  \begin{itemize}
    \item (Nested) for/do loops are best for parallelization
    \item Large loop counts are best
    \item Iterations of loops must be independent of each other
    \begin{itemize}
      \item To help compiler: restrict keyword (C), independent clause
      \item Use subscripted arrays, rather than pointer-indexed arrays
    \end{itemize}
    \item Data regions should avoid wasted bandwidth
    \begin{itemize}
      \item Can use directive to explicitly control sizes
    \end{itemize}
    \item Various annoying things can interfere with accelerated regions.
    \begin{itemize}
      \item Function calls within accelerated region must be inlineable.
      \item No IO
    \end{itemize}
  \end{itemize}
\end{frame}

\begin{frame}{\small OpenACC: Is it worth it?}
  \begin{itemize}
    \item High-level. No involvement of OpenCL, CUDA, etc
    \item Single source. No forking off a separate GPU code. Compile the same program for accelerators or serial, non-GPU programmers can play along.
    \item Efficient. Experience shows very favorable comparison to low-level implementations of same algorithms.
    \item Performance portable. Supports GPU accelreators and co-processors from multiple vendors, current and future versions.
    \item Incremental. Developers can port and tune parts of their application as resources and profiling dictates. No wholesale rewrite required. Which can be quick.
  \end{itemize}
\end{frame}

\begin{frame}
  \begin{itemize}
    \item[] Lecture derived from slides and presentations by
    \item Michael Wolfe, PGI
    \item Jeff Larkin, NVIDIA
    \item John Urbanic, PSC
    \item[] Search for OpenACC presentations at the GPU Technology Conference Website for further study \url{http://www.gputechconf.com/gtcnew/on-demand-gtc.php}
  \end{itemize}
\end{frame}

\setcounter{algorithm}{0}
\begin{frame}[allowframebreaks]{Exercise 1: Calculate pi by Numerical Integration}
  \begin{columns}
    \column{5cm}
    \begin{itemize}
      \item We know that
      \begin{align*}
        \int^1_0 \dfrac{4.0}{(1+x^2)}\, dx = \pi
      \end{align*}
      \item So numerically, we can approxiate pi as the sum of a number of rectangles
      \begin{align*}
        \sum^N_{i=0}\,F(x_i)\Delta x \approx \pi
      \end{align*}
      \item[] \fontsize{4}{5}{ Meadows et al, A ``hands-on'' introduction to OpenMP, SC09 }
    \end{itemize}
    \column{5cm}
    \begin{center}
      \includegraphics[width=4cm]{../OpenMP/pi}
    \end{center}
  \end{columns}

  \begin{algorithm}[H]
    \caption{Pseudo Code for Calculating Pi}
    \begin{algorithmic}
        \Function{calculate\_pi}{}
        \State $step \gets 1/n$
        \State $sum \gets 0$
        \Do{$i \gets 0\cdots n$}
        \State $x \gets (i+0.5)*step; sum \gets sum + 4/(1+x^2)$
        \EndDo
        \State $pi \gets sum * step$
        \EndFunction
    \end{algorithmic}
  \end{algorithm}
\end{frame}

\begin{frame}{Exercise 2: SAXPY}
  \begin{itemize}
    \item SAXPY is a common operation in computations with vector processors included as part of the BLAS routines
    \item[] $y\leftarrow \alpha x + y$
%    \item SAXPY is a combination of scalar multiplication and vector addition
    \item Write a SAXPY code to multiply a vector with a scalar.
  \end{itemize}
  \begin{algorithm}[H]
    \caption{Pseudo Code for SAXPY}
    \begin{algorithmic}
      \Program{saxpy}{}
      \State $n \gets$ some large number
      \State $x(1:n) \gets$ some number say, 1
      \State $y(1:n) \gets$ some other number say, 2
      \State $a \gets$ some other number ,say, 3
      \Do{$i \gets 1\cdots n$}
      \State $y_i \gets y_i + a * x_i$
      \EndDo
      \EndProgram{saxpy}
    \end{algorithmic}
  \end{algorithm}
\end{frame}

\begin{frame}[allowframebreaks]{Exercise 3: Matrix Multiplication}
  \begin{itemize}
    \item Most Computational code involve matrix operations such as matrix multiplication.
    \item Consider a matrix {\bf C} which is a product of two matrices {\bf A} and {\bf B}:
    \item[] Element {\it i,j} of {\bf C} is the dot product of the $i^{th}$ row of {\bf A} and $j^{th}$ column of {\bf B}
    \item Write a MATMUL code to multiple two matrices.
  \end{itemize}
  \begin{center}
    \includegraphics[width=0.3\textwidth]{../OpenMP/matmul}
  \end{center}

  \begin{algorithm}[H]
    \caption{Pseudo Code for MATMUL}
    \begin{algorithmic}
      \Program{matmul}{}
      \State $m,n \gets$ some\,large\,number $\le 1000$
      \State Define $a_{mn}, b_{nm}, c_{mm}$
      \State $a_{ij} \gets i+j; b_{ij} \gets i-j; c_{ij} \gets 0$
      \Do{$i \gets 1\cdots m$}
      \Do{$j \gets 1\cdots m$}
      \State $c_{i,j} \gets \sum^{n}_{k=1} a_{i,k}*b_{k,j}$
      \EndDo
      \EndDo
      \EndProgram{matmul}
    \end{algorithmic}
  \end{algorithm}
\end{frame}
\end{document}

